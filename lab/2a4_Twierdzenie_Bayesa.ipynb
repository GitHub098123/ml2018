{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wzory\n",
    "\n",
    "### Wzór Bayesa\n",
    "\n",
    "$$p(\\theta\\mid x) = \\dfrac{p(x\\mid \\theta)\\cdot p(\\theta)}{p(x)}$$\n",
    "\n",
    "Jeśli $\\theta$ może przyjmować tylko skończenie wiele wartości, tzn. $\\theta\\in\\{\\theta^1, \\ldots, \\theta^T\\}$, to możemy zapisać:\n",
    "\n",
    "$$p(x) = p(x, \\theta = \\mathrm{cokolwiek}) = p(x, \\theta=\\theta^1) + \\ldots + p(x, \\theta=\\theta^T) = p(x\\mid\\theta=\\theta^1)p(\\theta=\\theta^1) + \\ldots + p(x\\mid\\theta=\\theta^T)p(\\theta=\\theta^T)$$\n",
    "\n",
    "i wstawić to do powyższego wzoru (po co? tak będzie wygodniej, o czym przekonamy się za chwilę):\n",
    "\n",
    "$$p(\\theta\\mid x) = \\dfrac{p(x\\mid \\theta)\\cdot p(\\theta)}{p(x\\mid\\theta=\\theta^1)p(\\theta=\\theta^1) + \\ldots + p(x\\mid\\theta=\\theta^T)p(\\theta=\\theta^T)}$$\n",
    "\n",
    "Sam wzór Bayesa wynika wprost z definicji, więc jest dość prosty. Znacznie ciekawsze będzie to, co z nim zrobimy.\n",
    "\n",
    "### Wzór Bayesa pisany hiperpoprawnie\n",
    "\n",
    "Po dwóch stronach równości mamy dwie funkcje dwóch parametrów: $x$ oraz $\\theta$. Jeśli chcemy mieć równość liczb, a nie funkcji, to powinniśmy wybrać jakąś wartość $x$ - niech to będzie np. $x^1$ - oraz wartość $\\theta$ - powiedzmy $\\theta^t$ dla pewnego $t\\in\\{1, \\ldots, T\\}$ - i napisać:\n",
    "\n",
    "$$p(\\theta = \\theta^t\\mid x = x^1) = \\dfrac{p(x = x^1\\mid\\theta=\\theta^t)\\cdot p(\\theta=\\theta^t)}{p(x=x^1)}$$\n",
    "\n",
    "\n",
    "### Zadanie (niepunktowane)\n",
    "\n",
    "Udowodnić wzór Bayesa.\n",
    "\n",
    "### Wzór Bayesa - więcej zmiennych\n",
    "\n",
    "Zamiast $x$ i $\\theta$ oczywiście możemy wstawić do wzoru Bayesa więcej zmiennych. Zasada jest podobna, np.:\n",
    "\n",
    "$$p(\\theta,\\alpha\\mid x,y,z) = \\dfrac{p(x,y,z\\mid \\theta,\\alpha)\\cdot p(\\theta,\\alpha)}{p(x,y,z)}$$\n",
    "\n",
    "### Zadanie (niepunktowane)\n",
    "\n",
    "Jeśli np. $\\theta\\in\\{\\theta^1, \\ldots, \\theta^T\\}$ oraz $\\alpha\\in\\{\\alpha^1, \\ldots, \\alpha^A\\}$, to na co możemy podmienić $p(x,y,z)$ w mianowniku?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UCZENIE maszynowe\n",
    "\n",
    "Wróćmy teraz do pytania z końca poprzedniego notebooka.\n",
    "\n",
    "Odpowiedź, która brzmi sensownie, ale jest nieprawdziwa:\n",
    "\n",
    "\"Dane pochodzą i.i.d. z pewnego rozkładu prawdopodobieństwa $p$. Ten rozkład istnieje naprawdę, ale go nie znamy. Uczenie polega na znalezieniu tego rozkładu przy pomocy danych treningowych. Potem, mając ten rozkład, możemy wnioskować o zbiorze testowym. Przykładem może być sprawdzanie, czy moneta jest symetryczna. Rzucamy 1000 razy monetą i twierdzimy, że prawdopodobieństwo wypadnięcia orła to liczba wyrzuconych orłów podzielona przez liczbę rzutów.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 503, 1: 497})\n",
      "p(x=ORZEŁ) = 0.503\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "rng = np.random.RandomState(seed=43)\n",
    "# 0 - orzeł, 1 - reszka\n",
    "samples = [rng.choice(2) for _ in range(1000)]\n",
    "counted = Counter(samples)\n",
    "print(counted)\n",
    "print(\"p(x=ORZEŁ) =\", float(counted[0]/1000.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czyli moneta jest niesymetryczna? A może skoro jesteśmy tak blisko 50%, to moneta jednak jest symetryczna?\n",
    "\n",
    "Czy jeśli ktoś nas zapyta, jaki będzie wynik następnego rzutu monetą, to powinniśmy stwierdzić, że moneta jest niesymetryczna i nie wiemy, czy też obstawić orła, bo zgodnie z eksperymentem wypada częściej?\n",
    "\n",
    "Skąd w ogóle wiemy, że moneta może być niesymetryczna? A co jeśli moneta może być tylko niesymetryczna na korzyść reszki, tzn. albo moneta jest perfekcyjnie symetryczna, albo reszka wypada częściej? Czy wtedy powinniśmy stwierdzić, że moneta z naszego eksperymentu jest symetryczna, bo wypadło więcej orłów, czy też jednak stwierdzić, że jest niesymetryczna, bo przecież bardzo ciężko wykonać perfekcyjnie symetryczną monetę?\n",
    "\n",
    "itp. itd.\n",
    "\n",
    "Jeśli faktycznie zakładamy, że uczenie polega na wybieraniu rozkładu spośród dostępnych, to do każdego z powyższych pytań trzeba od nowa tworzyć strategię znalezienia odpowiedzi. To niedobrze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uczenie bayesowskie\n",
    "\n",
    "Odpowiedź, która brzmi dziwnie, ale jest poprawna:\n",
    "\n",
    "Nie ma czegoś takiego, jak uczenie się rozkładu. Żeby wykonać jakiekolwiek wnioskowanie statystyczne, musimy już mieć rozkład prawdopodobieństwa na wszystkich możliwych światach - oznaczmy go $p$. Ten rozkład nigdy się nie zmienia, jest on niezależny od czasu, obserwacji itp. Nasz świat to wynik jednego losowania z tego rozkładu.\n",
    "\n",
    "Możemy zapisać:\n",
    "$$p(\\mathrm{nasz\\ świat}) = p(\\mathrm{nasza\\ przeszłość}, \\mathrm{nasza\\ przyszłość})$$\n",
    "\n",
    "Jeśli chcemy mieć w ogóle możliwość wnioskowania o przyszłości na podstawie przeszłości, to musi zachodzić __nierówność__:\n",
    "\n",
    "$$p(\\mathrm{nasza\\ przyszłość}\\mid\\mathrm{dowolna\\ przeszłość}) = p(\\mathrm{nasza\\ przyszłość}) \\neq p(\\mathrm{nasza\\ przyszłość}\\mid\\mathrm{nasza\\ przeszłość})$$\n",
    "\n",
    "A więc założenie i.i.d. rozumiane dosłownie nie zachodzi - każda następna obserwacja jest zależna od poprzednich.\n",
    "\n",
    "### A teraz dużo wyjaśnień\n",
    "\n",
    "_Skąd bierzemy rozkład $p$ na wszystkich możliwych światach?_\n",
    "\n",
    "Trzeba go zgadnąć. Ewentualnie trzeba się z nim urodzić.\n",
    "\n",
    "_Co jeśli źle zgadniemy rozkład $p$?_\n",
    "\n",
    "Mamy problem. Duży. Wtedy nawet jeśli perfekcyjnie przeprowadzimy wnioskowanie na podstawie znanych nam obserwacji (przeszłości), to i tak nasze wnioski o przyszłości będą niepoprawne.\n",
    "\n",
    "_Czy nie da się jakoś sprawdzić, że nasze $p$ jest poprawne?_\n",
    "\n",
    "Nie.\n",
    "\n",
    "_Co z wnioskowaniem na temat przeszłości?_\n",
    "\n",
    "Jeśli chcemy mówić o wnioskowaniu na temat przeszłości, to trzeba dodać założenie, że tylko część przeszłości została zaobserwowana (z definicji cała przyszłość jest niezaobserwowana). Nie ma znaczenia to, że przeszłość się już \"wydarzyła\". Jeśli jej nie zaobserwowaliśmy, to z naszego punktu widzenia jest ona nieodróżnialna od przyszłości i wzory są analogiczne:\n",
    "\n",
    "$$p(\\mathrm{nasz\\ świat}) = p(\\mathrm{nasza\\ przeszłość\\ zaobserwowana}, \\mathrm{nasza\\ przeszłość\\ niezaobserwowana},\\mathrm{nasza\\ przyszłość})$$\n",
    "\n",
    "Wtedy nasza wiedza o niezaobserwowanej przeszłości jest tożsama z rozkładem:\n",
    "\n",
    "$$p(\\mathrm{nasza\\ przeszłość\\ niezaobserwowana}\\mid\\mathrm{nasza\\ przeszłość\\ zaobserwowana})$$\n",
    "\n",
    "Możemy już w ogóle nie myśleć o świecie w kategoriach przeszłości i przyszłości, ale skupić się na podziale na \"zdarzenia zaobserwowane\" i \"zdarzenia niezaobserwowane\". Wtedy możemy napisać:\n",
    "\n",
    "$$p(\\mathrm{nasz\\ świat}) = p(\\mathrm{zdarzenia\\ zaobserwowane}, \\mathrm{zdarzenia\\ niezaobserwowane})$$\n",
    "\n",
    "i wtedy nasza wiedza opisana jest rozkładem:\n",
    "\n",
    "$$p(\\mathrm{zdarzenia\\ niezaobserwowane}\\mid\\mathrm{zdarzenia\\ zaobserwowane})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Komentarz do powyższych wyjaśnień\n",
    "\n",
    "_Czy świat naprawdę tak działa?_\n",
    "\n",
    "Nikt nie wie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podstawy Machine Learningu: najprostszy model świata, wzór Bayesa, założenie i.i.d.\n",
    "\n",
    "Kiedy ktoś mówi o założeniu i.i.d., to tak naprawdę ma na myśli następujący model $p$:\n",
    "* mamy pewien parametr $\\theta$, którego nigdy nie będziemy w stanie zaobserwować,\n",
    "* znamy zbiór wszystkich możliwych wartości parametru $\\theta$ i znamy rozkład $p(\\theta)$,\n",
    "* obserwacje $x_1, x_2, \\ldots$ są i.i.d., ale __przy ustalonym $\\theta$__,\n",
    "* znamy rozkład warunkowy $p(x\\mid\\theta)$.\n",
    "\n",
    "Zapis $x_1, x_2, \\ldots$ oznacza, że obserwacji może być dowolnie dużo, potencjalnie nieskończenie wiele.\n",
    "\n",
    "W efekcie możemy napisać definicję całego rozkładu $p$:\n",
    "\n",
    "$p(\\theta, x_1=x^1, x_2=x^2, \\ldots) := $\n",
    "\n",
    "$p(x_1=x^1, x_2=x^2,\\ldots\\mid\\theta)p(\\theta) = $\n",
    "\n",
    "$p(x_1=x^1\\mid\\theta)p(x_2=x^2\\mid\\theta)\\ldots p(\\theta) = $\n",
    "\n",
    "$p(x=x^1\\mid\\theta)p(x=x^2\\mid\\theta)\\ldots p(\\theta)$\n",
    "\n",
    "### Zadanie (niepunktowane)\n",
    "\n",
    "Wytłumaczyć powyższe równości.\n",
    "\n",
    "Co one oznaczają?\n",
    "\n",
    "Czym się różnią?\n",
    "\n",
    "Która równość wynika z którego z powyższych założeń i w jaki sposób?\n",
    "\n",
    "### Kilka słów o parametrze $\\theta$\n",
    "\n",
    "Parametr $\\theta$ najłatwiej zrozumieć, korzystając z __niepoprawnej__ definicji uczenia maszynowego. Mówiła ona, że obserwując dane treningowe \"wybieramy\" rozkład, z którego one pochodzą. Wtedy:\n",
    "* znamy zbiór wszystkich możliwych wartości parametru $\\theta$ ---oznacza--- zdefiniowaliśmy rodzinę rozkładów, z której wybierzemy najlepszy,\n",
    "* obserwacje $x_1, x_2, \\ldots$ są i.i.d., ale przy ustalonym $\\theta$ ---oznacza--- wierzymy, że istnieje jeden \"prawdziwy\" rozkład i dane są z niego losowane niezależnie,\n",
    "* znamy rozkład warunkowy $p(x\\mid\\theta)$ ---oznacza--- każda wartość liczbowa $\\theta$ odpowiada jednemu rozkładowi na $x$ - mówimy, że jest to rodzina rozkładów na $x$ sparametryzowana parametrem $\\theta$.\n",
    "\n",
    "Nowym założeniem jest: \"znamy rozkład $p(\\theta)$\". Interpretujemy ten rozkład jako tzw. _wiedzę a priori_. Jest to nasze przekonanie o tym, który z możliwych rozkładów na $x$ jest bardziej prawdopodobny, przy czym nie patrzymy jeszcze w ogóle na zbiór treningowy.\n",
    "\n",
    "O parametrze $\\theta$ oraz o zbiorze testowym należy myśleć jako o zmiennych niezaobserwowanych. Jeśli ktoś woli interpretację przeszłość-przyszłość, to może myśleć następująco:\n",
    "* rozkład wszystkich możliwych światów to rozkład $p$ zdefiniowany jak powyżej,\n",
    "* w dalekiej przeszłości w naszym świecie została wylosowana i ustalona wartość parametru $\\theta$, niestety nie jest nam ona znana i nigdy jej nie poznamy,\n",
    "* od chwili ustalenia wartości $\\theta$ wszystkie sample są i.i.d. z rozkładu $p(x\\mid\\theta)$,\n",
    "* zbiór treningowy to nasza zaobserwowana przeszłość,\n",
    "* zbiór testowy to nasza przyszłość."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jak, gdzie i po co używać wzoru Bayesa\n",
    "\n",
    "Załóżmy, ze mamy $N$ obserwacji w zbiorze treningowym: $x_1=x^1, x_2=x^2, \\ldots, x_N=x^N$. Chcielibyśmy wnioskować na tej podstawie o wartości $x_{N+1}$, a więc chcemy policzyć:\n",
    "\n",
    "$$p(x_{N+1}\\mid x_1=x^1, x_2=x^2, \\ldots, x_N=x^N)$$\n",
    "\n",
    "Zrobimy to \"na raty\" - to znaczy najpierw spróbujemy wnioskować o $\\theta$ na podstawie zbioru treningowego, a następnie o $x_{N+1}$ na podstawie $\\theta$. Pierwszą część umożliwi nam wzór Bayesa, druga będzie prosta, bo $p(x_{N+1}\\mid\\theta) = p(x\\mid\\theta)$.\n",
    "\n",
    "Zapiszmy to wzorem. Ale zanim to zrobimy, umówmy się jeszcze, że:\n",
    "* cały ciąg obserwacji $x_1=x^1, x_2=x^2, \\ldots, x_N=x^N$ oznaczamy literką $D$ jak _Dataset_,\n",
    "* wszystkie możliwe wartości $\\theta$ to: $\\theta^1, \\theta^2, \\ldots, \\theta^T$.\n",
    "\n",
    "Teraz wzory:\n",
    "\n",
    "$p(x_{N+1}\\mid x_1=x^1, x_2=x^2, \\ldots, x_N=x^N) = p(x_{N+1}\\mid D) = $ \n",
    "\n",
    "$p(x_{N+1}\\mid\\theta=\\theta^1)p(\\theta=\\theta^1\\mid D) + \\ldots + p(x_{N+1}\\mid\\theta=\\theta^T)p(\\theta=\\theta^T\\mid D) = $\n",
    "\n",
    "$\\sum_{t=1}^T p(x_{N+1}\\mid\\theta=\\theta^t)p(\\theta=\\theta^t\\mid D)$\n",
    "\n",
    "### Zadanie z gwiazdką * (niepunktowane)\n",
    "\n",
    "Zgaduję, że w tym momencie (lub, niestety, znacznie wcześniej) wzorów jest za dużo, żeby wszystkie od razu rozumieć. Dlatego zróbmy zadanie.\n",
    "\n",
    "Dlaczego $p(x_{N+1}\\mid D) = \\sum_{t=1}^T p(x_{N+1}\\mid\\theta=\\theta^t, D)p(\\theta=\\theta^t\\mid D)$? Wytłumaczyć słownie, co ten wzór oznacza, i przeliczyć, że się zgadza.\n",
    "\n",
    "Dlaczego mogliśmy napisać zamiast powyższego wzór $p(x_{N+1}\\mid D) = \\sum_{t=1}^T p(x_{N+1}\\mid\\theta=\\theta^t)p(\\theta=\\theta^t\\mid D)$? Wytłumaczyć różnicę między tymi dwoma wzorami, wytłumaczyć słownie, dlaczego oba wzory są poprawne, rozpisać formalny dowód."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior, likelihood, posterior\n",
    "\n",
    "Jedyną niewiadomą w powyższych wzorach jest $p(\\theta=\\theta^t\\mid D)$. __Teraz__ użyjemy wzoru Bayesa:\n",
    "\n",
    "$$p(\\theta=\\theta^t\\mid D) = \\dfrac{p(D\\mid\\theta=\\theta^t)p(\\theta=\\theta^t)}{p(D)} = \\dfrac{p(D\\mid\\theta=\\theta^t)p(\\theta=\\theta^t)}{\\sum_{t=1}^T p(D\\mid\\theta=\\theta^t)p(\\theta=\\theta^t)}$$\n",
    "\n",
    "Koniec liczenia.\n",
    "\n",
    "Teraz ważne nazwy:\n",
    "* $p(\\theta=\\theta^t)$ w liczniku to tzw. __prior__ albo __wiedza a priori__, czyli wszystko to, co wiemy o wartościach $\\theta$ bez patrzenia na zbiór treningowy $D$,\n",
    "* $p(D\\mid\\theta=\\theta^t)$ w liczniku to tzw. __likelihood__, który mówi nam, jak bardzo prawdopodobny byłby dataset $D$, gdybyśmy znali prawdziwą wartość $\\theta$ i wynosiłaby ona $\\theta^t$,\n",
    "* $p(\\theta=\\theta^t\\mid D)$ po lewej stronie równości to tzw. __posterior__ albo __wiedza a posteriori__, czyli wszystko to, co wiemy o wartościach $\\theta$ po obejrzeniu zbioru treningowego $D$.\n",
    "\n",
    "Prior jest bardzo ważną częścią naszego modelu świata $p$. Zły prior utrudnia lub wręcz uniemożliwia dobre uczenie. Dobry prior przyspiesza uczenie. Niestety z dobrym priorem jest ten sam problem, co z modelem świata - trzeba go zgadnąć albo sie z nim urodzić.\n",
    "\n",
    "W praktyce da się zadziałać trochę lepiej. Mianowicie można wziąć posterior z innego problemu jako prior. Czy ktoś umie podać tu przykład z życia?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAP, MLE\n",
    "\n",
    "Wzór $p(x_{N+1}\\mid D) = \\sum_{t=1}^T p(x_{N+1}\\mid\\theta=\\theta^t)p(\\theta=\\theta^t\\mid D)$ z grubsza podsumowuje wszystko, co możemy wyciągnąć ze zbioru treningowego $D$. __Nie da się__ nauczyć lepiej.\n",
    "\n",
    "Oczywiście w praktyce wzór ten jest nie do policzenia...\n",
    "\n",
    "Główny problem to wielkość $T$. Jeśli np. mamy problem regresji liniowej z 10 parametrami, a każdy z nich jest czterobajtowym floatem, to $T = 2^{320}$.\n",
    "\n",
    "Cały Machine Learning to sztuka znalezienia dobrego przybliżenia powyższego wzoru. Omówmy na koniec dwa najpopularniejsze.\n",
    "\n",
    "#### Maximum A Posteriori\n",
    "\n",
    "Szukamy takiego $\\theta^t$, które zmaksymalizuje wartość liczbową posteriora:\n",
    "\n",
    "$$\\hat\\theta = \\operatorname{arg}\\max_{\\theta^t} p(\\theta=\\theta^t\\mid D)$$\n",
    "\n",
    "a następnie \"wybieramy\" to jedno $\\hat\\theta$ i tylko na jego podstawie dokonujemy predykcji:\n",
    "\n",
    "$$p(x_{N+1}\\mid D) \\cong p(x_{N+1}\\mid\\theta=\\hat\\theta)$$\n",
    "\n",
    "innymi słowy liczymy na to, że:\n",
    "\n",
    "$$p(\\theta=\\hat\\theta\\mid D)\\cong 1$$\n",
    "\n",
    "i wtedy:\n",
    "\n",
    "$$\\sum_{t=1}^T p(x_{N+1}\\mid\\theta=\\theta^t)p(\\theta=\\theta^t\\mid D) \\cong p(x_{N+1}\\mid\\theta=\\hat\\theta)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Likelihood Estimator\n",
    "\n",
    "Szukamy takiego $\\theta^t$, które zmaksymalizuje wartość liczbową posteriora:\n",
    "\n",
    "$$\\hat\\theta = \\operatorname{arg}\\max_{\\theta^t} p(D\\mid\\theta=\\theta^t)$$\n",
    "\n",
    "Jeśli $T$ jest skończoną liczbą naturalną, wtedy MLE to MAP z jednostajnym priorem. Jednostajny prior w praktyce jest złym pomysłem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie (niepunktowane)\n",
    "\n",
    "Mamy monetę, o której nie wiemy, czy jest symetryczna. Niech $\\theta$ przyjmuje wartości z przedziału $[0, 1]$ i reprezentuje prawdopodobieństwo wylosowania orła. Nasz prior to:\n",
    "* $p(\\theta=0.3) = 0.2$\n",
    "* $p(\\theta=0.5) = 0.7$\n",
    "* $p(\\theta=0.7) = 0.1$\n",
    "\n",
    "Niech $x$ oznacza rzuty monetą. Załóżmy, że $x_1 = \\mathrm{ORZEŁ}$.\n",
    "\n",
    "1. Zdefiniować $p(x\\mid\\theta)$.\n",
    "2. Policzyć $p(x_2 = \\mathrm{ORZEŁ} \\mid x_1 = \\mathrm{ORZEŁ})$\n",
    "3. Policzyć (podać liczbowe prawdopodobieństwa) rozkład $p(x_1, x_2)$. Pokazać, że to __nie__ są zmienne niezależne.\n",
    "4. Policzyć $p(x_2)$ metodą MAP.\n",
    "5. Policzyć $p(x_2)$ metodą MLE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
