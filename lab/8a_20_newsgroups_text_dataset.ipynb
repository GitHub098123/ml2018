{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "newsgroups = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opis datasetu:\n",
    "\n",
    "http://scikit-learn.org/stable/datasets/index.html#the-20-newsgroups-text-dataset\n",
    "\n",
    "Filtrowanie tekstu:\n",
    "\n",
    "http://scikit-learn.org/stable/datasets/index.html#filtering-text-for-more-realistic-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newsgroups.data\n",
      "type: <class 'list'> ; length: 11314 ; dtype: <class 'str'>\n",
      "newsgroups.target\n",
      "type: <class 'numpy.ndarray'> ; shape: (11314,) ; dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"newsgroups.data\")\n",
    "print(\"type:\", type(newsgroups.data), \"; length:\", len(newsgroups.data), \"; dtype:\", type(newsgroups.data[0]))\n",
    "print(\"newsgroups.target\")\n",
    "print(\"type:\", type(newsgroups.target), \"; shape:\", newsgroups.target.shape, \"; dtype:\", newsgroups.target.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 7\n",
      "Class label: alt.atheism\n",
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "############################################\n",
      "\n",
      "Class: 4\n",
      "Class label: comp.graphics\n",
      "A fair number of brave souls who upgraded their SI clock oscillator have\n",
      "shared their experiences for this poll. Please send a brief message detailing\n",
      "your experiences with the procedure. Top speed attained, CPU rated speed,\n",
      "add on cards and adapters, heat sinks, hour of usage per day, floppy disk\n",
      "functionality with 800 and 1.4 m floppies are especially requested.\n",
      "\n",
      "I will be summarizing in the next two days, so please add to the network\n",
      "knowledge base if you have done the clock upgrade and haven't answered this\n",
      "poll. Thanks.\n",
      "\n",
      "############################################\n",
      "\n",
      "Class: 4\n",
      "Class label: comp.os.ms-windows.misc\n",
      "well folks, my mac plus finally gave up the ghost this weekend after\n",
      "starting life as a 512k way back in 1985.  sooo, i'm in the market for a\n",
      "new machine a bit sooner than i intended to be...\n",
      "\n",
      "i'm looking into picking up a powerbook 160 or maybe 180 and have a bunch\n",
      "of questions that (hopefully) somebody can answer:\n",
      "\n",
      "* does anybody know any dirt on when the next round of powerbook\n",
      "introductions are expected?  i'd heard the 185c was supposed to make an\n",
      "appearence \"this summer\" but haven't heard anymore on it - and since i\n",
      "don't have access to macleak, i was wondering if anybody out there had\n",
      "more info...\n",
      "\n",
      "* has anybody heard rumors about price drops to the powerbook line like the\n",
      "ones the duo's just went through recently?\n",
      "\n",
      "* what's the impression of the display on the 180?  i could probably swing\n",
      "a 180 if i got the 80Mb disk rather than the 120, but i don't really have\n",
      "a feel for how much \"better\" the display is (yea, it looks great in the\n",
      "store, but is that all \"wow\" or is it really that good?).  could i solicit\n",
      "some opinions of people who use the 160 and 180 day-to-day on if its worth\n",
      "taking the disk size and money hit to get the active display?  (i realize\n",
      "this is a real subjective question, but i've only played around with the\n",
      "machines in a computer store breifly and figured the opinions of somebody\n",
      "who actually uses the machine daily might prove helpful).\n",
      "\n",
      "* how well does hellcats perform?  ;)\n",
      "\n",
      "thanks a bunch in advance for any info - if you could email, i'll post a\n",
      "summary (news reading time is at a premium with finals just around the\n",
      "corner... :( )\n",
      "--\n",
      "Tom Willis  \\  twillis@ecn.purdue.edu    \\    Purdue Electrical Engineering\n",
      "\n",
      "############################################\n",
      "\n",
      "Class: 1\n",
      "Class label: comp.sys.ibm.pc.hardware\n",
      "\n",
      "Do you have Weitek's address/phone number?  I'd like to get some information\n",
      "about this chip.\n",
      "\n",
      "\n",
      "############################################\n",
      "\n",
      "Class: 14\n",
      "Class label: comp.sys.mac.hardware\n",
      "From article <C5owCB.n3p@world.std.com>, by tombaker@world.std.com (Tom A Baker):\n",
      "\n",
      "\n",
      "My understanding is that the 'expected errors' are basically\n",
      "known bugs in the warning system software - things are checked\n",
      "that don't have the right values in yet because they aren't\n",
      "set till after launch, and suchlike. Rather than fix the code\n",
      "and possibly introduce new bugs, they just tell the crew\n",
      "'ok, if you see a warning no. 213 before liftoff, ignore it'.\n",
      "\n",
      "############################################\n",
      "\n",
      "Class: 16\n",
      "Class label: comp.windows.x\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Of course.  The term must be rigidly defined in any bill.\n",
      "\n",
      "\n",
      "I doubt she uses this term for that.  You are using a quote allegedly\n",
      "from her, can you back it up?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I read the article as presenting first an argument about weapons of mass\n",
      "destruction (as commonly understood) and then switching to other topics.\n",
      "The first point evidently was to show that not all weapons should be\n",
      "allowed, and then the later analysis was, given this understanding, to\n",
      "consider another class.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "############################################\n",
      "\n",
      "Class: 13\n",
      "Class label: misc.forsale\n",
      "There were a few people who responded to my request for info on\n",
      "treatment for astrocytomas through email, whom I couldn't thank\n",
      "directly because of mail-bouncing probs (Sean, Debra, and Sharon).  So\n",
      "I thought I'd publicly thank everyone.\n",
      "\n",
      "Thanks! \n",
      "\n",
      "(I'm sure glad I accidentally hit \"rn\" instead of \"rm\" when I was\n",
      "trying to delete a file last September. \"Hmmm... 'News?' What's\n",
      "this?\"....)\n",
      "\n",
      "############################################\n",
      "\n",
      "Class: 3\n",
      "Class label: rec.autos\n",
      "                                                                      \n",
      "ALL this shows is that YOU don't know much about SCSI.\n",
      "\n",
      "SCSI-1 {with a SCSI-1 controler chip} range is indeed 0-5MB/s\n",
      "and that is ALL you have right about SCSI\n",
      "SCSI-1 {With a SCSI-2 controller chip}: 4-6MB/s with 10MB/s burst {8-bit}\n",
      " Note the INCREASE in SPEED, the Mac Quadra uses this version of SCSI-1\n",
      " so it DOES exist. Some PC use this set up too.\n",
      "SCSI-2 {8-bit/SCSI-1 mode}:          4-6MB/s with 10MB/s burst\n",
      "SCSI-2 {16-bit/wide or fast mode}:  8-12MB/s with 20MB/s burst\n",
      "SCSI-2 {32-bit/wide AND fast}:     15-20MB/s with 40MB/s burst\n",
      " \n",
      "By your OWN data the \"Although SCSI is twice as fast as ESDI\" is correct\n",
      "With a SCSI-2 controller chip SCSI-1 can reach 10MB/s which is indeed\n",
      "\"20% faster than IDE\" {120% of 8.3 is 9.96}. ALL these SCSI facts have been\n",
      "posted to this newsgroup in my Mac & IBM info sheet {available by FTP on \n",
      "sumex-aim.stanford.edu (36.44.0.6) in the info-mac/report as \n",
      "mac-ibm-compare[version #].txt (It should be 173 but 161 may still be there)}\n",
      "\n",
      "Part of this problem is both Mac and IBM PC are inconsiant about what SCSI\n",
      "is which.  Though it is WELL documented that the Quadra has a SCSI-2 chip\n",
      "an Apple salesperson said \"it uses a fast SCSI-1 chip\" {Not at a 6MB/s,\n",
      "10MB/s burst it does not. SCSI-1 is 5MB/s maximum synchronous and Quadra\n",
      "uses ANsynchronous SCSI which is SLOWER}  It seems that Mac and IBM see\n",
      "SCSI-1 interface and think 'SCSI-1' when it maybe a SCSI-1 interface driven\n",
      "in the machine by a SCSi-2 controller chip in 8-bit mode {Which is MUCH\n",
      "FASTER then true SCSI-1 can go}.\n",
      "\n",
      "############################################\n",
      "\n",
      "Class: 2\n",
      "Class label: rec.motorcycles\n",
      "I have win 3.0 and downloaded several icons and BMP's but I can't figure out\n",
      "how to change the \"wallpaper\" or use the icons.  Any help would be appreciated.\n",
      "\n",
      "\n",
      "Thanx,\n",
      "\n",
      "-Brando\n",
      "\n",
      "############################################\n",
      "\n",
      "Class: 4\n",
      "Class label: rec.sport.baseball\n",
      "\n",
      "\n",
      "\n",
      "I've had the board for over a year, and it does work with Diskdoubler,\n",
      "but not with Autodoubler, due to a licensing problem with Stac Technologies,\n",
      "the owners of the board's compression technology. (I'm writing this\n",
      "from memory; I've lost the reference. Please correct me if I'm wrong.)\n",
      "\n",
      "Using the board, I've had problems with file icons being lost, but it's\n",
      "hard to say whether it's the board's fault or something else; however,\n",
      "if I decompress the troubled file and recompress it without the board,\n",
      "the icon usually reappears. Because of the above mentioned licensing\n",
      "problem, the freeware expansion utility DD Expand will not decompress\n",
      "a board-compressed file unless you have the board installed.\n",
      "\n",
      "Since Stac has its own product now, it seems unlikely that the holes\n",
      "in Autodoubler/Diskdoubler related to the board will be fixed.\n",
      "Which is sad, and makes me very reluctant to buy Stac's product since\n",
      "they're being so stinky. (But hey, that's competition.)\n",
      "-- \n",
      "\n",
      "############################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"Class:\", newsgroups.target[i])\n",
    "    print(\"Class label:\", newsgroups.target_names[i])\n",
    "    print(newsgroups.data[i])\n",
    "    print(\"\\n############################################\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Konwersja tekstu do tabelki feature'ów:\n",
    "\n",
    "http://scikit-learn.org/stable/datasets/index.html#converting-text-to-vectors\n",
    "\n",
    "Użyjemy `CountVectorizer` - pewnie działa gorzej niż `TfidfVectorizer`, ale jest bardziej zrozumiały:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text = [\n",
    "    \"Druga zwrotka bo zawsze chciałem zacząć od środka\",\n",
    "    \"Wśród kamienic plotka, że to horror w opłotkach\",\n",
    "    \"Jeden kolo ma ziarno i je pali aż parno\",\n",
    "    \"Wszędzie dym aż czarno można ciąć Husqvarną\",\n",
    "    \"A jak ziarno zasadzisz to Ci zniknie jak Vanish\",\n",
    "    \"Kliknie jak klawisz aż się wzdrygniesz jak panicz Yo\",\n",
    "    \"Bo to nie ziarnko pod farmerskie wdzianko\",\n",
    "    \"To Cię zarazi i nic nie poradzisz\"]\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv.fit(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aż': 0,\n",
       " 'bo': 1,\n",
       " 'chciałem': 2,\n",
       " 'ci': 3,\n",
       " 'ciąć': 4,\n",
       " 'cię': 5,\n",
       " 'czarno': 6,\n",
       " 'druga': 7,\n",
       " 'dym': 8,\n",
       " 'farmerskie': 9,\n",
       " 'horror': 10,\n",
       " 'husqvarną': 11,\n",
       " 'jak': 12,\n",
       " 'je': 13,\n",
       " 'jeden': 14,\n",
       " 'kamienic': 15,\n",
       " 'klawisz': 16,\n",
       " 'kliknie': 17,\n",
       " 'kolo': 18,\n",
       " 'ma': 19,\n",
       " 'można': 20,\n",
       " 'nic': 21,\n",
       " 'nie': 22,\n",
       " 'od': 23,\n",
       " 'opłotkach': 24,\n",
       " 'pali': 25,\n",
       " 'panicz': 26,\n",
       " 'parno': 27,\n",
       " 'plotka': 28,\n",
       " 'pod': 29,\n",
       " 'poradzisz': 30,\n",
       " 'się': 31,\n",
       " 'to': 32,\n",
       " 'vanish': 33,\n",
       " 'wdzianko': 34,\n",
       " 'wszędzie': 35,\n",
       " 'wzdrygniesz': 36,\n",
       " 'wśród': 37,\n",
       " 'yo': 38,\n",
       " 'zacząć': 39,\n",
       " 'zarazi': 40,\n",
       " 'zasadzisz': 41,\n",
       " 'zawsze': 42,\n",
       " 'ziarnko': 43,\n",
       " 'ziarno': 44,\n",
       " 'zniknie': 45,\n",
       " 'zwrotka': 46,\n",
       " 'środka': 47,\n",
       " 'że': 48}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wypiszmy nauczony słownik\n",
    "# domyślnie ignorowane są słowa jednoliterowe\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('aż', 'bo', 'chciałem', 'ci', 'ciąć', 'cię', 'czarno', 'druga', 'dym', 'farmerskie', 'horror', 'husqvarną', 'jak', 'je', 'jeden', 'kamienic', 'klawisz', 'kliknie', 'kolo', 'ma', 'można', 'nic', 'nie', 'od', 'opłotkach', 'pali', 'panicz', 'parno', 'plotka', 'pod', 'poradzisz', 'się', 'to', 'vanish', 'wdzianko', 'wszędzie', 'wzdrygniesz', 'wśród', 'yo', 'zacząć', 'zarazi', 'zasadzisz', 'zawsze', 'ziarnko', 'ziarno', 'zniknie', 'zwrotka', 'środka', 'że')\n"
     ]
    }
   ],
   "source": [
    "# tak będzie wygodniej\n",
    "features = list(zip(*sorted(cv.vocabulary_.items(), key=lambda tup: tup[1])))[0]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8x49 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 58 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cv.transform(train_text)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warto zaprzyjaźnić się z macierzami typu _sparse_: CSR, CSC i COO.\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/sparse.html\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csc_matrix.html\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 1 0 0 1 0 0 0 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
      "  1 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      "  0 0 0 0 1 0 0 1 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1\n",
      "  0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0\n",
      "  0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X.todense())\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: [8, 8, 9, 7, 9, 9, 7, 7]\n",
      "transformed: [8 7 8 7 8 9 7 6]\n"
     ]
    }
   ],
   "source": [
    "# policzmy, czy liczba słów w każdym zdaniu (z dokładnością do słów jednoliterowych) się zgadza\n",
    "print(\"original:\", [len(sentence.split()) for sentence in train_text])\n",
    "print(\"transformed:\", np.sum(X, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: [9, 8, 8, 7]\n",
      "transformed: [2 1 1 3]\n",
      "known words:\n",
      "   ['jak', 'kolo']\n",
      "   ['jak']\n",
      "   ['nie']\n",
      "   ['bo', 'ci', 'to']\n"
     ]
    }
   ],
   "source": [
    "# nauczony vectorizer ignoruje nowe słowa\n",
    "\n",
    "new_text = [\n",
    "    \"I jak by pytał kto ja ten kolo jestem\",\n",
    "    \"Mam plan niecny i szpetny jak Wujek Fester\",\n",
    "    \"Mam torbę ziaren ale nie mylić z towarem\",\n",
    "    \"Bo to podlewasz wokalem owocuje Ci tekstem\"]\n",
    "\n",
    "XX = np.array(cv.transform(new_text).todense())\n",
    "print(\"original:\", [len(sentence.split()) for sentence in new_text])\n",
    "print(\"transformed:\", np.sum(XX, axis=1))\n",
    "print(\"known words:\")\n",
    "for row in XX:\n",
    "    print(\"  \", [features[i] for i in np.nonzero(row)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11314x101631 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1103627 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zobaczmy na koniec statystyki datasetu \"newsgroups\"\n",
    "\n",
    "cv2 = CountVectorizer()\n",
    "cv2.fit(newsgroups.data)\n",
    "cv2.transform(newsgroups.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nie polecam:\n",
    "* iterować ręcznie po powyższej tabelce w pythonowej pętli,\n",
    "* konwertować bez potrzeby do reprezentacji gęstej (todense)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
