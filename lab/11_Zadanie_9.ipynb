{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Zadanie 9\n",
    "\n",
    "Zaimplementować:\n",
    "* funkcję `binary_crossentropy_pseudo_residuals`,\n",
    "* klasę `GammaLoss`,\n",
    "* klasę `GradientBoostingClassifier`.\n",
    "\n",
    "Dla uproszczenia zakładamy, że etykiety (y) są binarne, tzn. rozwiązujemy problem dwuklasowy. Predykcja modelu dotyczy klasy oznaczonej numerem 1 (podobnie jak w wypadku regresji logistycznej). Funkcją kosztu, którą chcemy optymalizować, jest więc binarna cross-entropia.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "\n",
    "https://en.wikipedia.org/wiki/Gradient_boosting#Algorithm\n",
    "\n",
    "https://en.wikipedia.org/wiki/Gradient_boosting#Gradient_tree_boosting\n",
    "\n",
    "Zakładamy, że każdy składowy model naszego klasyfikatora przewiduje __logits__ (oznaczane $\\hat{l}$), a nie prawdopodobieństwa! Dlatego też nasza funkcja kosztu będzie miała następującą postać:\n",
    "\n",
    "$$L(y,\\hat{l}) = -(y\\ln\\sigma(\\hat{l}) + (1-y)\\ln(1-\\sigma(\\hat{l})))$$\n",
    "\n",
    "Takie założenie jest o tyle wygodne, że skala logitsów jest nieograniczona (w przeciwieństwie do skali prawdopodobieństw), więc możemy \"bezkarnie\" dodawać predykcje wielu modeli.\n",
    "\n",
    "Uwaga (przypomnienie) - będziemy budowali klasyfikator z modeli __regresyjnych__.\n",
    "\n",
    "### `GradientBoostingClassifier`\n",
    "\n",
    "Klasa `GradientBoostingClassifier` przyjmuje w `__init__`:\n",
    "* `X` - tablicę o wymiarach (liczba_obserwacji, liczba_cech),\n",
    "* `y` - tablicę o wymiarach (liczba_obserwacji) z numerami klas (0 lub 1),\n",
    "* `n_models` - liczbę modeli, które mają zostać wytrenowane,\n",
    "* `model_cls` - klasę pojedynczego modelu regresyjnego, która przyjmuje w `__init__` jedynie `X` i `y` oraz ma zaimplementowaną metodę `predict` (patrz notebook 11a),\n",
    "* `train_fraction` - oznacza, jaki ułamek obserwacji ma być wylosowany do uczenia każdego ze składowych modeli (zredukowana_liczba_obserwacji = liczba_obserwacji * train_fraction), losujemy __bez powtórzeń__,\n",
    "* `initial_gamma` - wartość parametru $\\gamma$, od której rozpoczynamy optymalizację `GammaLoss`,\n",
    "* `gamma_n_steps` - liczba kroków optymalizacji `GammaLoss`,\n",
    "* `seed` - potrzebny np. przy losowaniu podzbioru obserwacji.\n",
    "\n",
    "Parametr `models` przechowuje listę nauczonych modeli w kolejności uczenia.\n",
    "\n",
    "Parametr `gammas` przechowuje listę znalezionych wartości $\\gamma$ w kolejności uczenia.\n",
    "\n",
    "Uczenie przebiega w następującej pętli (wykonywanej `n_models` razy):\n",
    "1. Wylosuj podzbiór obserwacji.\n",
    "2. Oblicz dotychczasową predykcję na tym podzbiorze.\n",
    "3. Oblicz pseudo residua `r_true` (patrz sekcja `binary_crossentropy_pseudo_residuals`).\n",
    "4. Wytrenuj kolejny model tak, aby przewidywał `r_true`, oblicz jego faktyczne predykcje `r`.\n",
    "5. Znajdź parametr $\\gamma$ (patrz sekcja `GammaLoss`).\n",
    "6. Dopisz model oraz parametr $\\gamma$ do `self.models` i `self.gammas`.\n",
    "\n",
    "Metoda `predict_logits` ma za zadanie przewidzieć wartości `logits` na danych `X`. Parametr `step` oznacza, ile (pierwszych w kolejności uczenia) modeli składowych użyć do predykcji. Będzie to przydatne przy uczeniu oraz wizualizowaniu nauczonego modelu. Domyślna wartość `None` oznacza użycie wszystkich modeli.\n",
    "\n",
    "### `binary_crossentropy_pseudo_residuals`\n",
    "\n",
    "Funkcja `binary_crossentropy_pseudo_residuals` przyjmuje dwie jednowymiarowe tablice `y_true` oraz `logits` o wymiarach (liczba_obserwacji,) i zwraca tablicę takiego samego wymiaru, która zawiera policzone element-wise pochodne cząstkowe $\\dfrac{\\partial L}{\\partial\\hat{l}}$ [wyprowadzamy wzór na pochodną przy tablicy].\n",
    "\n",
    "### `GammaLoss`\n",
    "\n",
    "Załóżmy, że wytrenowaliśmy już $k$ modeli składowych i chcemy dodać model $m_{k+1}$. W tym celu uczymy model $m_{k+1}$ na odpowiednio dobranych danych. Pozostaje jeszcze dobór parametru $\\gamma$. W tym celu rozwiązujemy jednowymiarowy problem optymalizacji przy użyciu klasy `GammaLoss` i dowolnego optimizera.\n",
    "\n",
    "Klasa `GammaLoss` przyjmuje w `__init__`:\n",
    "* `y_true` - tablica o wymiarze (zredukowana_liczba_obserwacji,) zawierająca prawdziwe etykiety,\n",
    "* `logits` - tablica o wymiarze (zredukowana_liczba_obserwacji,), dotychczasowa łączna predykcja modeli,\n",
    "* `r` - tablica o wymiarze (zredukowana_liczba_obserwacji,), predykcja modelu $m_{k+1}$\n",
    "i zapamiętuje te tablice - będą one potrzebne w metodzie `taylor`.\n",
    "\n",
    "Metoda `taylor` przyjmuje wartość $\\gamma$ i zwraca:\n",
    "* wartość kosztu $L(\\gamma) = \\mathcal{średnia}(-(y\\ln\\sigma(l+\\gamma r) + (1-y)\\ln(1-\\sigma(l+\\gamma r))))$\n",
    "* pochodną $\\dfrac{\\partial L}{\\partial\\gamma}$ [wyprowadzamy wzór na pochodną przy tablicy]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
